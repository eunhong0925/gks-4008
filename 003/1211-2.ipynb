{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities:\n",
      "[0.04242531377054976, 0.05161746508750221, 0.0522361675799894, 0.05214778150963408, 0.05108714866537034, 0.05241293972070002, 0.05170585115785752, 0.05250132579105533, 0.05285487007247658, 0.052766484002121264, 0.0530316422131872, 0.05258971186141064, 0.0522361675799894, 0.05250132579105533, 0.05241293972070002, 0.052943256142831886, 0.048258794414000356, 0.04984974368039597, 0.041099522715220084, 0.033321548523952624]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the 20 newsgroups dataset\n",
    "data = fetch_20newsgroups()\n",
    "categories = data.target_names\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "# Create a set of all unique words in the training data\n",
    "vocab_set = set()\n",
    "for dstr in train.data:\n",
    "    words = dstr.lower().split()\n",
    "    vocab_set.update(words)\n",
    "\n",
    "# Convert the set of unique words to a list\n",
    "vocab_list = list(vocab_set)\n",
    "\n",
    "# Calculate the prior probabilities for each category\n",
    "def prior_prob(categories):\n",
    "    category_counts = np.zeros(len(categories))\n",
    "\n",
    "    for i in range(len(train.data)):\n",
    "        GT_category = train.target_names[train.target[i]]\n",
    "\n",
    "        for j, s in enumerate(categories):\n",
    "            if GT_category == s:\n",
    "                category_counts[j] += 1\n",
    "\n",
    "    total_samples = len(train.data)\n",
    "    category_probabilities = category_counts / total_samples\n",
    "\n",
    "    return category_probabilities.tolist()  # Convert to Python list\n",
    "\n",
    "category_probabilities = prior_prob(categories)\n",
    "print(\"Prior Probabilities:\")\n",
    "print(category_probabilities)\n",
    "\n",
    "# Calculate the likelihood for each word given the category\n",
    "def likelihood(word, category, train_data, train_targets):\n",
    "    word_count_in_category = 0\n",
    "    total_words_in_category = 0\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        if train_targets[i] == categories.index(category):\n",
    "            total_words_in_category += len(train_data[i].split())\n",
    "            word_count_in_category += train_data[i].lower().split().count(word)\n",
    "\n",
    "    # Laplace smoothing to handle unseen words\n",
    "    alpha = 1\n",
    "    likelihood_prob = (word_count_in_category + alpha) / (total_words_in_category + alpha * len(vocab_list))\n",
    "\n",
    "    return likelihood_prob\n",
    "\n",
    "# Calculate the posterior probability for a given document and category\n",
    "def posterior_prob(doc, category, train_data, train_targets, prior_probs):\n",
    "    likelihoods = [likelihood(word, category, train_data, train_targets) for word in doc.lower().split()]\n",
    "    log_likelihood_sum = np.sum(np.log(likelihoods))\n",
    "    log_posterior = np.log(prior_probs[categories.index(category)]) + log_likelihood_sum\n",
    "    return np.exp(log_posterior)\n",
    "\n",
    "# Find the category with the highest posterior probability for a given document\n",
    "def predict_category(doc, categories, train_data, train_targets, prior_probs):\n",
    "    posterior_probs = [posterior_prob(doc, category, train_data, train_targets, prior_probs) for category in categories]\n",
    "    predicted_category_index = np.argmax(posterior_probs)\n",
    "    return categories[predicted_category_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Test Document:\n",
      "From: gdnikoli@undergrad.math.uwaterloo.ca (Greg Nikolic)\n",
      "Subject: Re: Who's next? Mormons and Jews?\n",
      "Organization: University of Waterloo\n",
      "Lines: 17\n",
      "\n",
      "In article <C5s5n0.DyJ@world.std.com> rjk@world.std.com (Robert J. Kolker) writes:\n",
      ">take their oath at the fortress. Lo Tepol Shaynit Matzadah. Matzadah will\n",
      ">not fall again!\n",
      "\n",
      "     These zealots. Holy fuck.\n",
      "\n",
      "     Israel. Armenia. Turkey. Greece. Croatia. Serbia. Bosnia. Russia. Germany.\n",
      "Iran. The Arab World.\n",
      "\n",
      "     War.\n",
      "\n",
      "\n",
      "-- \n",
      "     \"Please allow me to introduce myself.               SYMPATHY \n",
      "      I'm a man of wealth and taste.                   FOR THE DEVIL\n",
      "      I've been around for long, long years.            the Laibach  \n",
      "      Stolen many a man's soul, and faith.\"               remixes\n",
      "\n",
      "\n",
      "True Category: talk.politics.guns\n",
      "Predicted Category: alt.atheism\n"
     ]
    }
   ],
   "source": [
    "# Example: Predict the category for a random document from the test set\n",
    "random_test_doc_index = np.random.randint(0, len(test.data))\n",
    "random_test_doc = test.data[random_test_doc_index]\n",
    "true_category = test.target_names[test.target[random_test_doc_index]]\n",
    "\n",
    "predicted_category = predict_category(random_test_doc, categories, train.data, train.target, category_probabilities)\n",
    "\n",
    "print(\"Random Test Document:\")\n",
    "print(random_test_doc)\n",
    "print(f\"\\nTrue Category: {true_category}\")\n",
    "print(f\"Predicted Category: {predicted_category}\")\n",
    "\n",
    "# Measure accuracy on the test set\n",
    "test_predictions = [predict_category(doc, categories, train.data, train.target, category_probabilities) for doc in test.data]\n",
    "test_accuracy = accuracy_score(test.target, test_predictions)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
