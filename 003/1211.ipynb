{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups()\n",
    "categories = data.target_names\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of all unique words in the training data\n",
    "vocab_set = set()\n",
    "for dstr in train.data:\n",
    "    words = dstr.lower().split()\n",
    "    vocab_set.update(words)\n",
    "\n",
    "# Convert the set of unique words to a list\n",
    "vocab_list = list(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities:\n",
      "[0.04242531 0.05161747 0.05223617 0.05214778 0.05108715 0.05241294\n",
      " 0.05170585 0.05250133 0.05285487 0.05276648 0.05303164 0.05258971\n",
      " 0.05223617 0.05250133 0.05241294 0.05294326 0.04825879 0.04984974\n",
      " 0.04109952 0.03332155]\n"
     ]
    }
   ],
   "source": [
    "# Initialize counts for each word in each category\n",
    "word_counts = np.ones((len(categories), len(vocab_list)))  # Laplace smoothing with np.ones()\n",
    "\n",
    "# Calculate the prior probabilities for each category\n",
    "def prior_prob(categories):\n",
    "    category_counts = np.zeros(len(categories))\n",
    "\n",
    "    for i in range(len(train.data)):\n",
    "        GT_category = train.target_names[train.target[i]]\n",
    "\n",
    "        for j, s in enumerate(categories):\n",
    "            if GT_category == s:\n",
    "                category_counts[j] += 1\n",
    "\n",
    "    total_samples = len(train.data)\n",
    "    category_prob = category_counts / total_samples\n",
    "\n",
    "    return category_prob\n",
    "\n",
    "category_prob = prior_prob(categories)\n",
    "print(\"Prior Probabilities:\")\n",
    "print(category_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood(data, vocab_list, categories):\n",
    "    num_categories = len(categories)\n",
    "    num_words = len(vocab_list)\n",
    "\n",
    "    # Initialize counts for each word in each category with Laplace smoothing\n",
    "    word_counts = np.ones((num_categories, num_words))\n",
    "\n",
    "    # Count occurrences of each word in each category\n",
    "    for i in range(len(data)):\n",
    "        category_index = categories.index(train.target_names[train.target[i]])\n",
    "        words = data[i].lower().split()\n",
    "        for word in words:\n",
    "            if word in vocab_list:\n",
    "                word_index = vocab_list.index(word)\n",
    "                word_counts[category_index, word_index] += 1\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    likelihood_matrix = word_counts / np.sum(word_counts, axis=1, keepdims=True)\n",
    "\n",
    "    return likelihood_matrix\n",
    "\n",
    "# Example usage\n",
    "likelihood_matrix = compute_likelihood(train.data, vocab_list, categories)\n",
    "print(\"Likelihood Matrix:\")\n",
    "print(likelihood_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
